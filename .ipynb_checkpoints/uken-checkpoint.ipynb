{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e1d725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting monai\n",
      "  Downloading monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 10.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages (from monai) (1.24.4)\n",
      "Requirement already satisfied: torch>=1.9 in c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages (from monai) (2.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages (from torch>=1.9->monai) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages (from torch>=1.9->monai) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages (from torch>=1.9->monai) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages (from torch>=1.9->monai) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages (from torch>=1.9->monai) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages (from torch>=1.9->monai) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
      "Installing collected packages: monai\n",
      "Successfully installed monai-1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jovian\\anaconda3\\envs\\python38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131a531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from skimage.transform import resize\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "\n",
    "import zipfile\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from nilearn import plotting\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import monai\n",
    "from monai.transforms import Rand3DElasticd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96511fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = 'datasets/ULS23_DeepLesion3D/categories'\n",
    "\n",
    "def list_files_in_subfolders(directory):\n",
    "    subfolders_files = {}\n",
    "    for entry in os.listdir(directory):\n",
    "        subfolder_path = os.path.join(directory, entry)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            subfolders_files[entry] = [file[:-4] for file in os.listdir(subfolder_path)]\n",
    "    return subfolders_files\n",
    "\n",
    "files = list_files_in_subfolders(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb0f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(data, train_prop=0.6, val_prop=0.2, test_prop=0.2):\n",
    "    if train_prop + val_prop + test_prop != 1:\n",
    "        raise ValueError(\"The proportions must sum up to 1.\")\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    \n",
    "    # Calculate split indices\n",
    "    total_len = len(data)\n",
    "    train_end = int(total_len * train_prop)\n",
    "    val_end = train_end + int(total_len * val_prop)\n",
    "    \n",
    "    # Split the data\n",
    "    train_data = data[:train_end]\n",
    "    val_data = data[train_end:val_end]\n",
    "    test_data = data[val_end:]\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "train_data, val_data, test_data = [], [], []\n",
    "for subfolder, filenames in files.items():\n",
    "    train, val, test = split_list(filenames)\n",
    "    train_data.extend(train)\n",
    "    val_data.append(val)\n",
    "    test_data.append(test)\n",
    "    \n",
    "    \n",
    "def save_list(data, output_dir, filename):\n",
    "    file_path = os.path.join(output_dir, filename)\n",
    "    with open(file_path, 'w') as file:\n",
    "        for item in data:\n",
    "            file.write(f\"{item}\\n\")\n",
    "      \n",
    "output_dir = 'datasets'\n",
    "save_list(train_data, output_dir, \"deeplesion_train.txt\")\n",
    "save_list(val_data, output_dir, \"deeplesion_val.txt\")\n",
    "save_list(test_data, output_dir, \"deeplesion_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6abaadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoding3D(nn.Module):\n",
    "    def __init__(self, D, K, encoding):\n",
    "        super(Encoding3D, self).__init__()\n",
    "        self.D, self.K = D, K\n",
    "        self.codewords = nn.Parameter(torch.Tensor(K, D), requires_grad=True)\n",
    "        self.scale = nn.Parameter(torch.Tensor(K, D), requires_grad=True)\n",
    "        self.reset_params()\n",
    "        self.encoding = encoding\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(D, D),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def reset_params(self):\n",
    "        std1 = 1./((self.K*self.D)**(1/2))\n",
    "        self.codewords.data.uniform_(-std1, std1)\n",
    "        self.scale.data.uniform_(-1, 0)\n",
    "\n",
    "    def forward(self, X):\n",
    "        assert(X.size(1) == self.D)\n",
    "        B, D, T, H, W = X.size()\n",
    "        N = T * H * W\n",
    "        K = self.K\n",
    "\n",
    "        # Flatten X to (B, N, D) for processing\n",
    "        I = X.view(B, D, N).transpose(1, 2).contiguous()\n",
    "\n",
    "        # Calculate assignment weights A (B, N, K, D)\n",
    "        A = F.softmax(self.scale.view(1, 1, K, D) * (I.unsqueeze(2) - self.codewords.view(1, K, D)).pow(2), dim=2)\n",
    "\n",
    "        if not self.encoding:  # Embedding\n",
    "            E = (A * (I.unsqueeze(2) - self.codewords.view(1, K, D))).sum(1)\n",
    "            E = E.mean(dim=1)\n",
    "            gamma = self.fc(E)\n",
    "\n",
    "            E = (A * (I.unsqueeze(2) - self.codewords.view(1, K, D))).sum(2)\n",
    "            E = E.transpose(1, 2).contiguous().view(B, D, T, H, W)\n",
    "            y = gamma.view(B, D, 1, 1, 1)\n",
    "            E = F.relu_(E + E * y)\n",
    "        else:  # Encoding\n",
    "            E = (A * (I.unsqueeze(2) - self.codewords.view(1, K, D))).sum(1)\n",
    "\n",
    "        return E\n",
    "\n",
    "class EmbeddingModule3D(nn.Module):\n",
    "    def __init__(self, in_channels, ncodes=24):\n",
    "        super(EmbeddingModule3D, self).__init__()\n",
    "        self.encoding = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, in_channels, 1, bias=False),\n",
    "            nn.BatchNorm3d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Encoding3D(D=in_channels, K=ncodes, encoding=False),\n",
    "            nn.BatchNorm3d(in_channels),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(2 * in_channels, in_channels, 1, bias=True),\n",
    "            nn.BatchNorm3d(in_channels),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoding(x)\n",
    "        output = self.conv(torch.cat((x, encoded), dim=1))\n",
    "        return output\n",
    "\n",
    "class ResBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm3d(out_channels)\n",
    "        ) if in_channels != out_channels else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(residual)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class UNet3DWithKEM(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, base_n_filter=64):\n",
    "        super(UNet3DWithKEM, self).__init__()\n",
    "\n",
    "        self.enc1 = ResBlock3D(in_channels, base_n_filter)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "\n",
    "        self.enc2 = ResBlock3D(base_n_filter, base_n_filter * 2)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "\n",
    "        self.enc3 = ResBlock3D(base_n_filter * 2, base_n_filter * 4)\n",
    "        self.pool3 = nn.MaxPool3d(2)\n",
    "\n",
    "        # Bottleneck with KEM\n",
    "        self.bottleneck = ResBlock3D(base_n_filter * 4, base_n_filter * 8)\n",
    "        self.kem = EmbeddingModule3D(base_n_filter * 8)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose3d(base_n_filter * 8, base_n_filter * 4, kernel_size=2, stride=2)\n",
    "        self.dec3 = ResBlock3D(base_n_filter * 8, base_n_filter * 4)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose3d(base_n_filter * 4, base_n_filter * 2, kernel_size=2, stride=2)\n",
    "        self.dec2 = ResBlock3D(base_n_filter * 4, base_n_filter * 2)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose3d(base_n_filter * 2, base_n_filter, kernel_size=2, stride=2)\n",
    "        self.dec1 = ResBlock3D(base_n_filter * 2, base_n_filter)\n",
    "\n",
    "        self.final_conv = nn.Conv3d(base_n_filter, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.enc1(x)\n",
    "        pool1 = self.pool1(enc1)\n",
    "\n",
    "        enc2 = self.enc2(pool1)\n",
    "        pool2 = self.pool2(enc2)\n",
    "\n",
    "        enc3 = self.enc3(pool2)\n",
    "        pool3 = self.pool3(enc3)\n",
    "\n",
    "        bottleneck = self.bottleneck(pool3)\n",
    "        kem_output = self.kem(bottleneck)\n",
    "\n",
    "        up3 = self.up3(kem_output)\n",
    "        dec3 = self.dec3(torch.cat((up3, enc3), dim=1))\n",
    "\n",
    "        up2 = self.up2(dec3)\n",
    "        dec2 = self.dec2(torch.cat((up2, enc2), dim=1))\n",
    "\n",
    "        up1 = self.up1(dec2)\n",
    "        dec1 = self.dec1(torch.cat((up1, enc1), dim=1))\n",
    "\n",
    "        output = self.final_conv(dec1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcdb2e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): UNet3DWithKEM(\n",
       "    (enc1): ResBlock3D(\n",
       "      (conv1): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(1, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (pool1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (enc2): ResBlock3D(\n",
       "      (conv1): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (pool2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (enc3): ResBlock3D(\n",
       "      (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (pool3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (bottleneck): ResBlock3D(\n",
       "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (kem): EmbeddingModule3D(\n",
       "      (encoding): Sequential(\n",
       "        (0): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Encoding3D(\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (up3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (dec3): ResBlock3D(\n",
       "      (conv1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (up2): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (dec2): ResBlock3D(\n",
       "      (conv1): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (up1): ConvTranspose3d(32, 16, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (dec1): ResBlock3D(\n",
       "      (conv1): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (final_conv): Conv3d(16, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet3DWithKEM(base_n_filter=16)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94f948a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train set is: 450\n",
      "The length of val set is: 7\n"
     ]
    }
   ],
   "source": [
    "# CREATE A TORCH DATASET\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import nibabel as nib\n",
    "import torch\n",
    "\n",
    "class DeepLesion_dataset(Dataset):\n",
    "    '''\n",
    "    Assumes that labels are already unzipped\n",
    "    '''\n",
    "    def __init__(self, image_dir, label_dir, list_dir, split, clip=-1, transform=None):\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.sample_list = [line.strip('\\n') for line in open(os.path.join(list_dir, 'deeplesion_'+self.split+'.txt'))]\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.sample_list[idx]\n",
    "        image_path = os.path.join(self.image_dir, filename+'_lesion_01.nii.gz')\n",
    "        label_path = os.path.join(self.label_dir, filename+'_lesion_01.nii.gz')\n",
    "        image = nib.load(image_path).get_fdata()\n",
    "        label = nib.load(label_path).get_fdata()\n",
    "        image = np.expand_dims(np.squeeze(image), axis=0)\n",
    "        label = np.expand_dims(np.squeeze(label), axis=0)\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        sample = {'image':image, 'label':label}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        sample['case_name'] = filename\n",
    "        return sample\n",
    "    \n",
    "\n",
    "image_dir = 'datasets/ULS23_DeepLesion3D/images'\n",
    "label_dir = 'datasets/ULS23_DeepLesion3D/labels'\n",
    "list_dir = 'datasets'\n",
    "\n",
    "transform = Rand3DElasticd(\n",
    "    keys=['image', 'label'],\n",
    "    sigma_range=(5, 8),\n",
    "    magnitude_range=(50, 100),\n",
    "    prob=0.5, \n",
    "    translate_range=5, \n",
    "    rotate_range=np.pi/12, \n",
    "    scale_range=(0.1, 0.1, 0.1), \n",
    "    padding_mode='border')\n",
    "    \n",
    "db_train = DeepLesion_dataset(image_dir, label_dir, list_dir, 'train', transform=transform)\n",
    "db_val = DeepLesion_dataset(image_dir, label_dir, list_dir, 'val', transform=transform)\n",
    "db_test = DeepLesion_dataset(image_dir, label_dir, list_dir, 'test', transform=transform)\n",
    "print(\"The length of train set is: {}\".format(len(db_train)))\n",
    "print(\"The length of val set is: {}\".format(len(db_val)))\n",
    "\n",
    "trainloader = DataLoader(db_train, batch_size=1, shuffle=True)\n",
    "valloader = DataLoader(db_val, batch_size=1, shuffle=True)\n",
    "\n",
    "# i_batch, sampled_batch = next(enumerate(trainloader))\n",
    "# print(sampled_batch['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb189e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(preds, labels):\n",
    "    \"\"\"\n",
    "    Compute the Dice loss between predictions and labels.\n",
    "    preds: Tensor of shape (batch_size, 1, 128, 256, 256)\n",
    "    labels: Tensor of shape (batch_size, 128, 256, 256)\n",
    "    \"\"\"\n",
    "    # Ensure the predictions are in [0,1] by applying sigmoid\n",
    "    preds = torch.sigmoid(preds)\n",
    "    \n",
    "    # Remove the channel dimension from preds to match labels' shape\n",
    "    preds = preds.squeeze(1)\n",
    "    \n",
    "    # Calculate intersection and union\n",
    "    intersection = (preds * labels).sum(dim=(1, 2, 3))\n",
    "    union = preds.sum(dim=(1, 2, 3)) + labels.sum(dim=(1, 2, 3))\n",
    "    \n",
    "    # Compute Dice coefficient and Dice loss\n",
    "    dice_coeff = (2. * intersection + 1e-6) / (union + 1e-6)  # Adding a small epsilon to avoid division by zero\n",
    "    dice_loss = 1 - dice_coeff\n",
    "    \n",
    "    # Return the average Dice loss over the batch\n",
    "    return dice_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "625fdc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                        | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\t2.00% complete. 440.53 seconds elapsed in epoch.\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/10 [08:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 49\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Track training progress\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m(i_batch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(trainloader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% complete. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimer()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds elapsed in epoch.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m     end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python38\\lib\\site-packages\\monai\\data\\meta_tensor.py:282\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    281\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 282\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python38\\lib\\site-packages\\torch\\_tensor.py:1386\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1386\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1388\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def save_checkpoint(snapshot_dir, epoch_num, history, best_model, curr_model):\n",
    "    # Save history\n",
    "    save_history_path = os.path.join(snapshot_dir, f\"epoch_{epoch_num}_history.npz\")\n",
    "    np.savez_compressed(save_history_path, history=history)\n",
    "    # Save best model\n",
    "    best_model_path = os.path.join(snapshot_dir, f\"epoch_{epoch_num}_best.pth\")\n",
    "    torch.save(best_model, best_model_path)\n",
    "    # Save current model\n",
    "    save_model_path = os.path.join(snapshot_dir, f\"epoch_{epoch_num}.pth\")\n",
    "    torch.save(curr_model, save_model_path)\n",
    "    print(f\"Saved model to {save_model_path}, {best_model_path}\")\n",
    "\n",
    "base_lr = 0.05\n",
    "snapshot_dir = 'snapshots'\n",
    "patience = 3\n",
    "max_epoch = 10\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=base_lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "# Make snapshots dir\n",
    "if not os.path.exists(snapshot_dir):\n",
    "    os.makedirs(snapshot_dir)\n",
    "\n",
    "\n",
    "max_iterations = max_epoch * len(trainloader)\n",
    "best_val_loss = float('inf')\n",
    "overall_start = timer()\n",
    "history = []\n",
    "wait = 0\n",
    "best_model = None\n",
    "total_epochs = 0\n",
    "# For each epoch\n",
    "iterator = tqdm(range(max_epoch), ncols=100)\n",
    "for epoch_num in iterator:\n",
    "    start = timer()\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for i_batch, sampled_batch in enumerate(trainloader):\n",
    "        image_batch, label_batch = sampled_batch[\"image\"], sampled_batch[\"label\"]\n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "        outputs = model(image_batch)\n",
    "        loss = dice_loss(outputs, label_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # Track training progress\n",
    "        print(\n",
    "            f\"Epoch: {epoch_num}\\t{100 * (i_batch + 1) / len(trainloader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.\",\n",
    "            end=\"\\r\",\n",
    "        )\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(trainloader)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():  # No need to track gradients during validation\n",
    "        for i_batch, sampled_batch in enumerate(valloader):\n",
    "            image_batch, label_batch = sampled_batch[\"image\"], sampled_batch[\"label\"]\n",
    "            image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "            outputs = model(image_batch)\n",
    "            loss = dice_loss(outputs, label_batch)\n",
    "            total_val_loss += loss_dice.item()\n",
    "            \n",
    "    avg_val_loss = total_val_loss / len(valloader)\n",
    "    history.append([avg_train_loss, avg_val_loss])\n",
    "    \n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    total_epochs += 1\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model = deepcopy(model.state_dict())\n",
    "        wait = 0  # Reset wait counter\n",
    "        print(f\"Validation loss improved to {val_loss:.4f}. Saving model...\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Stopping early due to lack of improvement in validation loss.\")\n",
    "            save_checkpoint(snapshot_dir, epoch_num, history, best_model, model.state_dict())\n",
    "            break\n",
    "\n",
    "    # Save occasionally\n",
    "    if (epoch_num + 1) % 10 == 0:\n",
    "        save_checkpoint(snapshot_dir, epoch_num, history, best_model, model.state_dict())\n",
    "        \n",
    "iterator.close()\n",
    "total_time = timer() - overall_start\n",
    "print(\n",
    "    f\"{total_time:.2f} total seconds elapsed. {total_time / (total_epochs+1):.2f} seconds per epoch.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797309b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
